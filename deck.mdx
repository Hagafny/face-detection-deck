import './styles.css'
import { Steps, Notes, useSteps } from 'mdx-deck'
import { CodeSurfer, CodeSurferColumns, Step } from 'code-surfer'
import { vsDark, nightOwl } from '@code-surfer/themes'
import { Button } from './components/Button/Button.js'
import { RandomlyPlaced } from './layouts/RandomlyPlaced.js'
import { ImageDeck, DECK_IMAGES } from './images/ImageDeck.js'
import { FadeIn } from './components/FadeIn.js'
import { IntroGrid } from './layouts/IntroGrid.js'
import { ZoomSteps } from './components/ZoomSteps/ZoomSteps.js'
import { SideBySide } from './layouts/SideBySide.js'
import myTheme from './theme/theme'
import { SlideLayout } from './layouts/SlideLayout.js'
import CropSimulator from './components/CropSimulator.js'
import CropSimulatorPhase from './components/CropSimulatorPhase.js'
import MLModalLoader from './components/MLModalLoader.js'
import { AnimatedBulletList } from './layouts/AnimatedBulletList.js';
import IntroSlide from './slides/introSlide.js'
import FaceDetectionSlide from './slides/FaceDetectionSlide.js'
import Tile from './components/Tile.js'
import SimulatorSlide from './slides/SimulatorSlide.js'
import NormalSimulatorSlide from './slides/NormalSimulatorSlide.js'
import GoodCropBadCropSlide from './slides/GoodCropBadCropSlide.js'
import MixtilesSlide from './slides/MixtilesSlide.js'
import SmartCropSlide from './slides/SmartCropSlide.js'
import ThankYouSlide from './slides/ThankYouSlide.js'
import CodeExample from './components/CodeExample.js'

export const theme = myTheme
const cropExample = 'ron2.jpg'

<Head>
  <title>Face Detection </title>
</Head>
<MLModalLoader/>
<IntroSlide showDetections={false} />

---

<MixtilesSlide />

---
<h1>The User Experience</h1>
<iframe style={{ width: '85vw', height: '750px'}} src="https://www.mixtiles.com/photos" title="Mixtiles Tile Picker"></iframe>

---

<SlideLayout title='Customers Recieved Poorly Cropped Tiles' direction='column'>
    <div
      style={{
        display: 'flex',
        alignItems: 'center',
        justifyContent: 'space-around',
        marginTop: '200px'
      }}
    >
      <ZoomSteps>
        <ImageDeck src={'support.png'} style={{ width: '256px', height: '256px' }}/>
        <ImageDeck src={'satisfaction.png'} style={{ width: '256px', height: '256px' }}/> 
      </ZoomSteps>
    </div>
</SlideLayout>

---

<SmartCropSlide />
<Notes>

-- Speaker Notes

-- Another note

</Notes>

---

<SlideLayout title='Tensorflow' screenHeight justifyContent='center'>
  <ImageDeck
    width={'50%'}
    height={'50%'}
    src='tenserflow.png'
    styles={{ backgroundSize: 'cover' }}
  />
</SlideLayout>

---

# Object Detection

---

<SlideLayout title='Tensorflow Summary' direction='column'>
    <div
      style={{
        display: 'flex',
        alignItems: 'center',
        justifyContent: 'space-around',
        marginTop: '200px'
      }}
    >
      <ZoomSteps>
        <ImageDeck src={'easy.png'} style={{ width: '256px', height: '256px' }}/>
        <ImageDeck src={'speedometer.png'} style={{ width: '256px', height: '256px' }}/>
        <ImageDeck src={'delivery-box.png'} style={{ width: '256px', height: '256px' }}/> 
      </ZoomSteps>
    </div>
</SlideLayout>

---

## 90% of Mixtiles uploads are humans

---

<SlideLayout title='FaceAPI' screenHeight justifyContent='center'>
  <ImageDeck
    width={'50%'}
    height={'50%'}
    src='faceapi.png'
    styles={{ backgroundSize: 'cover' }}
  />
</SlideLayout>



---

<FaceDetectionSlide />

---

<CodeSurfer theme={vsDark}>

```js
import { useEffect, useState } from 'react'
import * as faceapi from 'face-api.js';

const useFaceApiModels = () => {
  const [modelsLoaded, setModelsLoaded] = useState(false)

  useEffect(() => {
      const loadModels = async () => {
        await Promise.all([
          faceapi.loadTinyFaceDetectorModel('/models'),
          faceapi.loadFaceLandmarkModel('/models'),
          faceapi.loadFaceExpressionModel('/modls')
        ])

        setModelsLoaded(true)
      };

      loadModels();
    }, []);

    return modelsLoaded
}

```

```js showNumbers 5:19
import { useEffect, useState } from 'react'
import * as faceapi from 'face-api.js';

const useFaceApiModels = () => {
  const [modelsLoaded, setModelsLoaded] = useState(false)

  useEffect(() => {
      const loadModels = async () => {
        await Promise.all([
          faceapi.loadTinyFaceDetectorModel('/models'),
          faceapi.loadFaceLandmarkModel('/models'),
          faceapi.loadFaceExpressionModel('/modls')
        ])

        setModelsLoaded(true)
      };

      loadModels();
    }, []);

    return modelsLoaded
}
```

```js showNumbers 1:20
import React, { useEffect, useRef  } from 'react';
import useFaceApiModels from './useFaceApiModels';

function CodeExample() {
  const modelsLoaded = useFaceApiModels()
  const imageRef = useRef()

  useEffect(() => {
    const detectFaces = async () => {
        if (modelsLoaded && imageRef.current) {
            // Ready to use Face Detection
        }
    }
    detectFaces()
  }, [modelsLoaded, imageRef])

  return (
    <img ref={imageRef} src='example.png'} />
  );
}

```

```js 11:13
import React, { useEffect, useRef  } from 'react';
import useFaceApiModels from './useFaceApiModels';

function CodeExample() {
  const modelsLoaded = useFaceApiModels()
  const imageRef = useRef()

  useEffect(() => {
    const detectFaces = async () => {
        if (modelsLoaded && imageRef.current) {
            const detections = await faceapi.detectAllFaces(
              imageRef.current,
              new faceapi.TinyFaceDetectorOptions())
        }
    }
    detectFaces()
  }, [modelsLoaded, imageRef])

  return (
    <img ref={imageRef} src='example.png' />
  );
}
```

```js 11:15
import React, { useEffect, useRef  } from 'react';
import useFaceApiModels from './useFaceApiModels';

function CodeExample() {
  const modelsLoaded = useFaceApiModels()
  const imageRef = useRef()

  useEffect(() => {
    const detectFaces = async () => {
        if (modelsLoaded && imageRef.current) {
            const detections = await faceapi.detectAllFaces(
              imageRef.current,
              new faceapi.TinyFaceDetectorOptions())
              .withFaceLandmarks()
              .withFaceExpressions();
        }
    }
    detectFaces()
  }, [modelsLoaded, imageRef])

  return (
    <img ref={imageRef} src='example.png' />
  );
}
```

</CodeSurfer>

---

# How do we use the detections?

---

<CodeSurferColumns themes={[vsDark]}>

<Step>

```js 11:15
import React, { useEffect, useRef  } from 'react';
import useFaceApiModels from './useFaceApiModels';

function CodeExample() {
  const modelsLoaded = useFaceApiModels()
  const imageRef = useRef()

  useEffect(() => {
    const detectFaces = async () => {
        if (modelsLoaded && imageRef.current) {
            const detections = await faceapi.detectAllFaces(
              imageRef.current,
              new faceapi.TinyFaceDetectorOptions())
              .withFaceLandmarks()
              .withFaceExpressions();
        }
    }
    detectFaces()
  }, [modelsLoaded, imageRef])

  return (
    <img ref={imageRef} src={exampleImage}} />
  );
}
```

<CodeExample />

</Step>

<Step>

```js
import React, { useEffect, useRef  } from 'react';
import useFaceApiModels from './useFaceApiModels';

function CodeExample() {
  const modelsLoaded = useFaceApiModels()
  const imageRef = useRef()
  const canvasRef = useRef()

  useEffect(() => {
    const detectFaces = async () => {
        if (modelsLoaded && imageRef.current) {
            const detections = await faceapi.detectAllFaces(
              imageRef.current,
              new faceapi.TinyFaceDetectorOptions())
              .withFaceLandmarks()
              .withFaceExpressions();

              const canvas = canvasRef.current
        }
    }
    detectFaces()
  }, [modelsLoaded, imageRef, canvasRef])

  return (
    <div style={{position: 'relative'}}>
      <img ref={imageRef} src={exampleImage}} />
      <canvas ref={canvasRef} style={{position: 'absolute', top: 0, left: 0}} />
    </div>
  );
}
```

<CodeExample />

</Step>

<Step>

```js
import React, { useEffect, useRef  } from 'react';
import useFaceApiModels from './useFaceApiModels';

function CodeExample() {
  const modelsLoaded = useFaceApiModels()
  const imageRef = useRef()
  const canvasRef = useRef()

  useEffect(() => {
    const detectFaces = async () => {
        if (modelsLoaded && imageRef.current) {
            const detections = await faceapi.detectAllFaces(
              imageRef.current,
              new faceapi.TinyFaceDetectorOptions())
              .withFaceLandmarks()
              .withFaceExpressions();

              const canvas = canvasRef.current

              const displaySize = { 
                width: imageRef.current.width,
                height: imageRef.current.height 
              };

              faceapi.matchDimensions(canvas, displaySize);
        }
    }
    detectFaces()
  }, [modelsLoaded, imageRef, canvasRef])

  return (
    <div style={{position: 'relative'}}>
      <img ref={imageRef} src={exampleImage}} />
      <canvas ref={canvasRef} style={{position: 'absolute', top: 0, left: 0}} />
    </div>
  );
}
```

<CodeExample />

</Step>

<Step>

```js
import React, { useEffect, useRef  } from 'react';
import useFaceApiModels from './useFaceApiModels';

function CodeExample() {
  const modelsLoaded = useFaceApiModels()
  const imageRef = useRef()
  const canvasRef = useRef()

  useEffect(() => {
    const detectFaces = async () => {
        if (modelsLoaded && imageRef.current) {
            const detections = await faceapi.detectAllFaces(
              imageRef.current,
              new faceapi.TinyFaceDetectorOptions())
              .withFaceLandmarks()
              .withFaceExpressions();

              const canvas = canvasRef.current

              const displaySize = { 
                width: imageRef.current.width,
                height: imageRef.current.height 
              };

              faceapi.matchDimensions(canvas, displaySize);

              faceapi.draw.drawDetections(canvas, detections)
        }
    }
    detectFaces()
  }, [modelsLoaded, imageRef, canvasRef])

  return (
    <div style={{position: 'relative'}}>
      <img ref={imageRef} src={exampleImage}} />
      <canvas ref={canvasRef} style={{position: 'absolute', top: 0, left: 0}} />
    </div>
  );
}
```

<CodeExample useDetections={true} />

</Step>

<Step>

```js 26:28
import React, { useEffect, useRef  } from 'react';
import useFaceApiModels from './useFaceApiModels';

function CodeExample() {
  const modelsLoaded = useFaceApiModels()
  const imageRef = useRef()
  const canvasRef = useRef()

  useEffect(() => {
    const detectFaces = async () => {
        if (modelsLoaded && imageRef.current) {
            const detections = await faceapi.detectAllFaces(
              imageRef.current,
              new faceapi.TinyFaceDetectorOptions())
              .withFaceLandmarks()
              .withFaceExpressions();

              const canvas = canvasRef.current

              const displaySize = { 
                width: imageRef.current.width,
                height: imageRef.current.height 
              };

              faceapi.matchDimensions(canvas, displaySize);

              faceapi.draw.drawDetections(canvas, detections)
              faceapi.draw.drawFaceExpressions(canvas, detections)
        }
    }
    detectFaces()
  }, [modelsLoaded, imageRef, canvasRef])

  return (
    <div style={{position: 'relative'}}>
      <img ref={imageRef} src={exampleImage}} />
      <canvas ref={canvasRef} style={{position: 'absolute', top: 0, left: 0}} />
    </div>
  );
}
```

<CodeExample useDetections={true} useExpressions={true} />

</Step>

<Step>

```js 26:29
import React, { useEffect, useRef  } from 'react';
import useFaceApiModels from './useFaceApiModels';

function CodeExample() {
  const modelsLoaded = useFaceApiModels()
  const imageRef = useRef()
  const canvasRef = useRef()

  useEffect(() => {
    const detectFaces = async () => {
        if (modelsLoaded && imageRef.current) {
            const detections = await faceapi.detectAllFaces(
              imageRef.current,
              new faceapi.TinyFaceDetectorOptions())
              .withFaceLandmarks()
              .withFaceExpressions();

              const canvas = canvasRef.current

              const displaySize = { 
                width: imageRef.current.width,
                height: imageRef.current.height 
              };

              faceapi.matchDimensions(canvas, displaySize);

              faceapi.draw.drawDetections(canvas, detections)
              faceapi.draw.drawFaceExpressions(canvas, detections)
              faceapi.draw.drawFaceLandmarks(canvas, detections)
        }
    }
    detectFaces()
  }, [modelsLoaded, imageRef, canvasRef])

  return (
    <div style={{position: 'relative'}}>
      <img ref={imageRef} src={exampleImage}} />
      <canvas ref={canvasRef} style={{position: 'absolute', top: 0, left: 0}} />
    </div>
  );
}
```

<CodeExample useDetections={true} useExpressions={true} useLandmarks={true} />

</Step>

</CodeSurferColumns>

---

<SlideLayout title='face-api.js Summary' direction='column'>
   <AnimatedBulletList>
    <span>Detects only one type of object - faces, and it does it very well</span>
    <span>If we go with the tiny model, it can weigh as light as 200KB </span>
      </AnimatedBulletList>
</SlideLayout>

---

<NormalSimulatorSlide imageURL={cropExample} />

---

<SimulatorSlide imageURL={cropExample} />

---

<GoodCropBadCropSlide />

---

# Results

---

<SlideLayout title='Possible Improvements' direction='column'>
  <AnimatedBulletList>
    <span>Won’t work on images without faces (10% of uploads) </span>
    <span>If we go with the most lightweight model, it will not detect some faces </span>
    <span>Has an impact on bundle size. We can always look for ways to optimize this </span>
  </AnimatedBulletList>
</SlideLayout>

---

<SlideLayout title='Lookiung To The Future'>
Chat GPT and Dalle Image here
</SlideLayout>

---

<SlideLayout title='Summary' direction='column'>
   <AnimatedBulletList>
    <span>How cropping became a big issue. </span>
    <span>Our process of experimentation with Tensorflow </span>
    <span>Code examples of how face detection works in general and how we used it to build a “smart crop” algorithm </span>
   </AnimatedBulletList>
</SlideLayout>

---

<ThankYouSlide />